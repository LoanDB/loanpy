"""Adapt or reconstruct words, i.e. surf horizontally and vertically
through the network of life"""

from ast import literal_eval
from collections import Counter, OrderedDict
from itertools import count, cycle, product
from math import prod
from operator import itemgetter

from tqdm import tqdm

from loanpy.helpers import (
    Etym,
    apply_edit,
    clusterise,
    combine_ipalists,
    editops,
    flatten,
    get_howmany,
    list2regex,
    pick_minmax,
    tokenise)
from loanpy.qfysc import Qfy


def read_scdictlist(scdictlist):
    """
    Called by loanpy.adrc.Adrc.__init__. \
Reads sound correspondence dictionary list generated by \
loanpy.qfysc.Qfy.get_sound_corresp from a file.

    :param scdictlist: The path to the sound correspondence dictionaries
    :type scdictlist: pathlib.PosixPath | str | None

    :returns: Only the first 4 of the 6 dicts because the last two are \
not necessary for any computations. Returns 4 times None if \
input is None.
    :rtype: [None, None, None, None] | [dict, dict, dict, dict]

    :Example:

    >>> from loanpy.adrc import read_scdictlist, __file__
    >>> from pathlib import Path
    >>> read_scdictlist(None)
    [None, None, None, None]
    >>> path2sc = Path(__file__).parent / "tests" \
/ "input_files" / "sc_ad_3cogs.txt"
    >>> read_scdictlist(path2sc)
    [{'a': ['a'], 'd': ['d'], 'j': ['j'], 'l': ['l'], 'n': ['n'], \
't͡ʃː': ['t͡ʃ'], 'ɣ': ['ɣ'], 'ɯ': ['i']}, {'a<a': 6, 'd<d': 1, 'i<ɯ': 1, \
'j<j': 1, 'l<l': 1, 'n<n': 1, 't͡ʃ<t͡ʃː': 1, 'ɣ<ɣ': 2}, {'a<a': [1, 2, 3], \
'd<d': [2], 'i<ɯ': [1], 'j<j': [3], 'l<l': [2], 'n<n': [3], 't͡ʃ<t͡ʃː': [1], \
'ɣ<ɣ': [1, 2]}, \
{'VCCVC': ['VCCVC'], 'VCVC': ['VCVC'], 'VCVCV': ['VCVCV']}]

    """
    if scdictlist is None:
        return [None]*4
    with open(scdictlist, "r", encoding="utf-8") as f:
        return literal_eval(f.read())[:4]


def move_sc(sclistlist, whichsound, out):
    """
    Called by loanpy.adrc.Adrc.read_sc. \
    Moves sound correspondences. \
A list of stacks where param <whichsound> indicates \
which stack to pick. Append its second element to out and pop its first.

    :param sclistlist: A word where every phoneme has been replaced with a \
list of **all** possible sound correspondences ranked by likelihood, \
i.e. how often \
each sound correspondence occurred in the data. \
(Heuristic correspondences have frequency 0.)
    :type sclistlist: list of lists

    :param whichsound: The index of the phoneme to move from sclistlist to \
the output
    :type whichsound: int

    :param out: The future output of loanpy.adrc.Adrc.adapt/reconstruct
    :type out: list of lists

    :returns: List with the selected stack popped, and the new out variable.
    :rtype: tuple: (list of lists, list of lists)

    :Example:

    >>> from loanpy.adrc import move_sc
    >>>  # Transfer phoneme #1 of list #0 from sclistlist to out
    >>> move_sc(sclistlist=[["x", "x"]], whichsound=0, out=[[]])
    ([["x"]], [["x"]])
    >>>  # Transfer phoneme #1 of list #0 from sclistlist to out
    >>> move_sc(sclistlist=[["x", "x"], ["y", "y"], ["z"]], whichsound=0, \
out=[["a"], ["b"], ["c"]])
    ([["x"], ["y", "y"], ["z"]], [["a", "x"], ["b"], ["c"]])
    >>>  # Transfer phoneme #1 of list #2 from sclistlist to out
    >>> move_sc(sclistlist=[["", "$"], ["", "$"], ["Z", "2", "$"]], \
whichsound=2, out=[["o"], ["r"], ["f"]])
    [["", "$"], ["", "$"], ["2", "$"]], [["o"], ["r"], ["f", "2"]])
    """

    out[whichsound].append(sclistlist[whichsound][1])  # move sound #1 to out
    sclistlist[whichsound].pop(0)  # move input by 1 (remove sound #0)
    return sclistlist, out  # tuple


class Adrc(Qfy):
    """
    Read etymological data and information about it generated by loanpy.\
qfysc.py and use it to predict loanword adaptations (lateral transfers) \
and reconstructions (vertical transfers).

    The first 9 parameters are passed on to loanpy.qfysc.Qfy to inherit \
12 attributes (of which 8 are inherited from loanpy.helpers.Etym). The last \
parameter is passed on to __init__ to create 5 own attributes, \
so 17 attributes \
in total.

    Define own attributes:

    :param scdictlist: Path to data generated with \
loanpy.qfysc.Qfy.get_sound_corresp. (\
Dicts 0, 1, 2 capture phonological \
correspondences, dicts 3, 4, 5 phonotactic ones. dict0/dict3: the actual \
correspondences, dict1/dict4: How often each correspondence \
occurs in the data, \
dict2/dict5: list of cognate sets in which each correspondence occurs.
    :type scdictlist: pathlib.PosixPath | str | None, default=None

    :Exmaple:

    >>> from loanpy.adrc import Adrc, __file__
    >>> from pathlib import Path
    >>> path2folder = Path(__file__).parent / "tests" \
/ "input_files"
    >>> path2sc = path2folder / "sc_ad_3cogs.txt"
    >>> path2forms = path2folder / "forms_3cogs_wot.csv"
    >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
forms_csv=path2forms, \
source_language="WOT", target_language="EAH", \
mode="reconstruct", \
most_frequent_phonotactics=2)
    >>> adrc_obj.scdict  # sound correspondence dictionary
    {'a': ['a'], 'd': ['d'], 'j': ['j'], 'l': ['l'], 'n': ['n'], \
't͡ʃː': ['t͡ʃ'], 'ɣ': ['ɣ'], 'ɯ': ['i']}
    >>> adrc_obj.sedict  # sum of examples dictionary
    {'a<a': 6, 'd<d': 1, 'i<ɯ': 1, 'j<j': 1, 'l<l': 1, \
'n<n': 1, 't͡ʃ<t͡ʃː': 1, 'ɣ<ɣ': 2}
    >>> adrc_obj.edict  # examples dictionary
    {'a<a': [1, 2, 3], 'd<d': [2], 'i<ɯ': [1], 'j<j': [3], \
'l<l': [2], 'n<n': [3], 't͡ʃ<t͡ʃː': [1], 'ɣ<ɣ': [1, 2]}
    >>> adrc_obj.scdict_phonotactics  # phonotactic correspondence dictionary
    {'VCCVC': ['VCCVC'], 'VCVC': ['VCVC'], 'VCVCV': ['VCVCV']}
    >>> adrc_obj.workflow
    OrderedDict()
    >>> len(adrc_obj.__dict__)  # 5 own + 11 attributes inherited \
from loanpy.qfysc.Qfy
    17

    """
    def __init__(self,  # 9 args for inheritance from from loanpy.qfysc.Qfy
                 forms_csv=None,
                 source_language=None,
                 target_language=None,
                 most_frequent_phonotactics=9999999,
                 phonotactic_inventory=None,
                 mode=None,
                 connector=None,
                 scdictbase=None,
                 vfb=None,
                 # only this will be read here.
                 scdictlist=None):
        # inherit from loanpy.qfysc.Qfy
        super().__init__(forms_csv=forms_csv,
                         source_language=source_language,
                         target_language=target_language,
                         most_frequent_phonotactics=most_frequent_phonotactics,
                         phonotactic_inventory=phonotactic_inventory,
                         mode=mode,
                         connector=connector,
                         scdictbase=scdictbase,
                         vfb=vfb)
        # read here - was extracted by loanpy.qfysc.Qfy and written to file
        (self.scdict, self.sedict, self.edict,
            self.scdict_phonotactics) = read_scdictlist(scdictlist)
        # sound correspondence dictionaries

        self.workflow = OrderedDict()  # will be filled by self.adapt()

    def get_diff(self, sclistlist, ipa):
        """Called by loanpy.adrc.Adrc.read_sc. \
Tells how much it would cost to move each \
sound correspondence \
by looking up the number of occurences of the current \
and the next phoneme \
in the sum-of-example dictionary and subtracting the \
latter from the former. \
(They were sorted by decreasing frequency by \
loanpy.qfysc.Qfy.get_sound_corresp) \
The bigger the difference the greater the cost to move it. \
Since the higher the sum \
of examples for each phoneme in a word, the more \
credible its etymology.

    :param sclistlist: A word where every phoneme has been replaced with a \
list of possible sound correspondences ranked by likelihood, i.e. how often \
each sound correspondence occurred in the data.
    :type sclistlist: list of lists

    :param ipa: The tokenised/clusterised input string
    :type ipa: list

    :returns: A list of integers where the integers indicate the cost of \
moving the phoneme that is at the same index in the sound correspondence list.
    :rtype: list of int

    :Example:

    >>> from loanpy.adrc import Adrc, __file__
    >>> from pathlib import Path
    >>> path2folder = Path(__file__).parent / "tests" \
/ "input_files"
    >>> path2sc = path2folder / "sc_ad_3cogs.txt"
    >>> path2forms = path2folder / "forms_3cogs_wot.csv"
    >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
forms_csv=path2forms, \
source_language="WOT", target_language="EAH")
    >>> adrc_obj.get_diff(sclistlist=[["d", "x", "$"], ["a", "x", "$"], \
["d", "x", "$"], ["a", "x", "$"]], ipa=["d", "a", "d", "a"])
    [1, 6, 1, 6]
        """
        # difference in nr of examples between current and next sound corresp
        # for each phoneme or cluster in a word
        difflist = []  # this will be returned
        # loop through phonemes/clusters of word
        for idx, sclist in enumerate(sclistlist):
            # get nr of occurences of current sound corresp (0 if not in dict)
            firstsc = self.sedict.get(ipa[idx] + self.connector + sclist[0], 0)
            # check for two exceptions:
            if len(sclist) == 2:  # exception 1: if list has reached the end...
                # ... it can never be moved again. Bc nth bigger than inf.
                difflist.append(float("inf"))  # = stop button
                continue  # check next phoneme
            # exception 2: no data avail. ~ nr of occurences == 0 ~ heuristics
            # don't loop through heuristics before all data available used
            if firstsc == 0:
                difflist.append(9999999)  # = pause/freeze button...
                continue  # ... can be unfrozen by inf (= end of list)

            # get nr of occurences of next sound corresp (0 if no data avail.)
            nextsc = self.sedict.get(ipa[idx] + self.connector + sclist[1], 0)
            # append diffrnc between current & next sound corresp to outputlist
            difflist.append(firstsc - nextsc)

        return difflist

    def read_sc(self, ipa, howmany=1):
        """
        Called by loanpy.adrc.Adrc.adapt and loanpy.adrc.Adrc.reconstruct. \
Replaces every phoneme of a word with a list of phonemes \
that it can correspond \
to, meeting following conditions: a. The product of the length of each list \
is just minimally above the number indicated in \
param <howmany> (leftover will \
be sliced away later). b. Those phonemes are chosen that diminish the sum of \
examples of the predicted word the least. (Sum of example means \
adding together how many times \
each phoneme of the predicted reconstruction corresponded \
to the aligned phoneme of the source word in the etymological data.)

        :param ipa: a tokenised/clusterised word
        :type ipa: list

        :param howmany: How many words would this be, if combinatorics were \
applied. This is the false positive rate if the prediction is wrong but \
the false positive rate -1 if the prediction is right. (Say \
1 guess is made and it is correct, then there are 0 false positives, \
i.e. howmany-1. \
If 1 guess is made and it's wrong then there will be 1 false positive.)
        :type howmany: int, default=1

        :returns: The information to which sounds each input \
sound can correspond.
        :rtype: list of lists

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"input_files"
        >>> path2sc = path2folder / "sc_ad_handmade.txt"
        >>> adrc_obj = Adrc(scdictlist=path2sc)
        >>> adrc_obj.read_sc(ipa="dade", howmany=1)  # 1*1*1*1 = 1
        [["d"], ["a"], ["d"], ["y"]]
        >>> adrc_obj.read_sc(ipa="dade", howmany=4)  # 2*2*1*1 = 4
        [["d", "tʰ"], ["a", "e"], ["d"], ["y"]]
        >>> adrc_obj.read_sc(ipa="dade", howmany=160)  # 4*5*4*2 = 160
        [["d", "tʰ", "t", "tː"], \
["a", "e", "i", "o", "u"], ["d", "tʰ", "t", "tː"], ["y", "u"]]
        >>> adrc_obj.read_sc(ipa="dade", howmany=float("inf"))  # all possible
        [["d", "tʰ", "t", "tː"], \
["a", "e", "i", "o", "u"], ["d", "tʰ", "t", "tː"], ["y", "u", "e"]]
        """

        # pick all sound correspondences from dictionary
        sclistlist = [self.scdict[i] for i in ipa]
        # if howmany is bigger/equal than their product, return all of them.
        if howmany >= prod([len(scl) for scl in sclistlist]):
            return sclistlist
        # else add a stop sign to the end of each sound corresp list
        sclistlist = [sclist+["$"] for sclist in sclistlist]
        # pick only 1st (=most likely/frequent) sound corresp for each phoneme
        out = [[i[0]] for i in sclistlist]
        # decide which sound corresp to accept next. Stop if product reached
        while howmany > prod([len(scl) for scl in out]):
            # get by how much each new sound corresp would diminish the nse
            difflist = self.get_diff(sclistlist, ipa)  # e.g. [0, 0, 1, 2]
            minimum = min(difflist)  # how much is lowest possible difference?
            # get list index for all phonemes making the least difference.
            indices = [i for i, v in enumerate(difflist) if v == minimum]
            if len(indices) == 1:  # if only 1 element makes least difference
                sclistlist, out = move_sc(sclistlist, indices[0], out)  # Use!
                continue  # jump up to while and check if product is reached
            # but if multiple elements are the minimum...
            difflist2 = difflist  # ...remember the differences they make, ...
            idxpool = cycle(indices)  # ... and cycle through them...
            while (difflist2 == difflist and  # ... until diffs change, or:
                   howmany > prod([len(scl) for scl in out])):  # ">" (!)
                # pick next sound correspondence
                sclistlist, out = move_sc(sclistlist, next(idxpool), out)
                # check the differences all phonemes would make
                difflist2 = self.get_diff(sclistlist, ipa)
                # latest if a sound hits end of list: turns 2 inf, breaks loop

        return out

    def reconstruct(self,
                    ipastr,
                    howmany=1,
                    clusterised=True,
                    phonotactics_filter=False,
                    vowelharmony_filter=False,
                    sort_by_nse=False,
                    *args):  # so sanity.eval_one can pass on more args
        """
        Predicts past forms of a word based on data. Should \
theoretically also work for forward reconstructions, but not tested yet. \
Word initial and word final sounds/clusters are \
tagged with a "#". In addition to \
this, every word gets a "#-" and a "-#" added to the front \
and back of its list of tokens, \
to capture \
prefixes and suffixes that may have appeared or disappeared. \
If parameters <phonotactics_filter>, <vowelharmony_filter> and <sort_by_nse> \
are all set to False or zero, \
the output will be a regular expression of the type "^(a|b)(c|d)(e)$". If one \
of those parameters is set to True or non-zero, \
combinatorics will be applied and the \
outputted regular expression will be of the type "(^ace$|^ade$|^bce$|^bde$)".

        :param ipastr: The non-tokenised input word. \
Should consist only of \
valid IPA-characters, as defined in ipa_all.csv's column "ipa", even though \
the tokeniser handles invalid characters quite well. Make sure this is not \
an empty string.
        :type ipastr: str

        :param howmany: Indicate how many guesses should be made. If all \
predictions are wrong, this is the same as the false positive rate. \
If the right prediction is among the guesses, it is the false positive \
rate plus one.
        :type howmany: int, default=1

        :param clusterised: If set to True, this will slice up the input \
word into consonant and vowel clusters to look for them as keys in the sound \
change dictionary.
        :type clusterised: bool, default=True

        :param phonotactics_filter: Indicate whether words \
should be filtered out \
from the final result if their phonotactic profile does not occur in the \
phonotactic inventory of target language.
        :type phonotactics_filter: bool, default=False

        :param vowelharmony_filter: Indicate whether words violating the \
constraint front-back vowel harmony (a word can contain only \
front or only \
back vowels) should be filtered out.
        :type vowelharmony_filter: bool, default=False

        :param sort_by_nse: Indicate whether results \
should be sorted by their \
normalised sum of examples (likelihood measure for etymologies). \
Can be costly to calculate but still cheaper and more elegant than \
replacing itertool's product function, which does this (from its \
documentation): "The leftmost iterators are in the \
outermost for-loop, so the \
output tuples cycle in a manner similar to an odometer \
(with the rightmost element changing on every iteration)"
        :type sort_by_nse: bool, default=False

        :param args: This does nothing. The purpose of this is \
for loanpy.sanity.eval_one to be able \
to pass on a consistent list of args to both adapt and reconstruct.

        :returns: A regular expression **approximating** \
the indicated number of predicted reconstructions, if \
params <phonotactics_filter>, <vowelharmony_filter> and <sort_by_nse> \
were all set to False or zero and the output thus is a regular expression \
of the type "^(a|b)(c|d)(e)$". A regular expression **exactly** \
the indicated number of predicted reconstructions, if one \
of those aforementioned 3 parameters is set to True or non-zero, \
thus combinatorics is applied and the \
outputted regular expression is of the type "(^ace$|^ade$|^bce$|^bde$)".

        :rtype: str

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"input_files"
        >>> path2sc = path2folder / "sc_rc_3cogs.txt"
        >>> adrc_obj = Adrc(scdictlist=path2sc, mode="reconstruct")
        >>> adrc_obj.reconstruct("kriekrie")  # clusterise, missing from data
        '#kr, ie, kr, ie# not old'
        >>> adrc_obj.reconstruct("kriekrie", clusterised=False)  # tokenise
        '#k, i, e, k, i, e# not old'
        >>> adrc_obj.reconstruct("aːruː")
        '^(a)(n)(a)(at͡ʃi)$'
        >>> adrc_obj.reconstruct("aːruː", howmany=2)
        '^(a)(n)(a)(at͡ʃi|ɣ)$'
        >>> path2forms = path2folder / "forms_3cogs_wot.csv"
        >>> # read etymological data to get phonotactic inventory for filter
        >>> adrc_obj = Adrc(forms_csv=path2forms, source_language="H", \
target_language="EAH", scdictlist=path2sc, mode="reconstruct")
        >>> adrc_obj.reconstruct("aːruː", \
howmany=2, phonotactics_filter=True)  \
# only CVCV in inventory
        '^anaɣ$'
        >>> adrc_obj.reconstruct("aːruː", howmany=1, \
phonotactics_filter=True)  \
# low howmany -> empty filter
        'wrong phonotactics'
        >>> adrc_obj.vow2fb["i"] = "B"  # let's assume "i" was a back vowel
        >>> adrc_obj.reconstruct("aːruː", howmany=4, vowelharmony_filter=True)
        '^anaɣ$'
        >>> # "anaat͡ʃi" got filtered out b/c it contains \
a front and back vowel
        >>> # violation of constraint "vowelharmony_filter" in \
terms of optimality theory
        >>> adrc_obj.reconstruct("aːruː", howmany=1, \
vowelharmony_filter=True)  \
# low howmany -> empty filter
        'wrong vowel harmony'
        >>> adrc_obj.vow2fb["i"] = "F"  # make "i" a front vowel again
        >>> adrc_obj.reconstruct("aːruː", howmany=4, \
vowelharmony_filter=True)  \
# nothing gets filtered
        "^anaat͡ʃi$|^anaɣ$"
        >>> adrc_obj.reconstruct("aːruː", howmany=4, sort_by_nse=True)
        >>> # examples per phoneme divided by word length is higher for "anaɣ"
        "^anaɣ$|^anaat͡ʃi$"
        """

        # slice up the input the way it's indicated in param <clusterised>
        ipalist = clusterise(ipastr) if clusterised else tokenise(ipastr)

        # apply same tagging process as in loanpy.qfysc.Qfy.align_clusterwise
        ipalist[0], ipalist[-1] = f"#{ipalist[0]}", f"{ipalist[-1]}#"
        ipalist = ["#-"] + ipalist + ["-#"]

        # if phonemes missing from sound correspondence dict, return which ones
        if not all(phon in self.scdict for phon in ipalist):
            return ', '.join([i for i in ipalist
                              if i not in self.scdict]) + " not old"

        # read the correct number of sound correspondences per phoneme
        out = self.read_sc(ipalist, howmany)

        # skip combinatorics, instead return result if these 3 params are False
        if all(i is False or i == 0 for i in
               [phonotactics_filter, vowelharmony_filter, sort_by_nse]):
            return f"^{''.join([list2regex(i) for i in out])}$"

        # if one of the 3 params is True however, apply combinatorics
        out = ["".join(i).replace("-", "") for i in product(*out)]

        # apply first filter if indicated (wrong phontactics out)
        if phonotactics_filter is True:
            out = [i for i in out if self.word2phonotactics(i) in
                   self.phonotactic_inventory]
            if out == []:
                return "wrong phonotactics"

        # apply 2nd filter if indicated (wrong vowelharmony_filter out)
        if vowelharmony_filter is True:
            out = [i for i in out if self.has_harmony(i)]
            if out == []:
                return "wrong vowel harmony"

        # sort results by decreasing likelihood (normalised sum of examples)
        if sort_by_nse:
            out_nse = [(i, self.get_nse(ipastr, i)) for i in out]  # get nse
            out_max = pick_minmax(out_nse, sort_by_nse, max)
            out = list(dict.fromkeys(out_max + out))

        # can't have float in slice, but howmany=float("inf") is possible now
        if howmany != float("inf"):
            out = out[:howmany]
        return f"^{'$|^'.join(out)}$"  # turn list to regular expression

    def repair_phonotactics(self,
                            ipastr,
                            max_repaired_phonotactics=2,
                            max_paths2repaired_phonotactics=1,
                            deletion_cost=100,
                            insertion_cost=49,
                            show_workflow=False):
        """
        Called by loanpy.adrc.Adrc.adapt. \
Repairs the phonotactic structure of a word.

        :param ipastr: The input word. Will be tokenised if string.
        :type ipastr: list | str

        :param max_repaired_phonotactics: The maximum number of target \
phonotactic structures \
into which to turn the source structure.
        :type max_repaired_phonotactics: int, default=2

        :param max_paths2repaired_phonotactics: The maximum number of \
different cheapest ways to \
turn the source structure into the target structure
        :type max_paths2repaired_phonotactics: int, default=1

        :param deletion_cost: The cost of deleting a segment
        :type deletion_cost: int | float, default=100

        :param insertion_cost: The cost of inserting a segment
        :type insertion_cost: int | float, default=49

        :param show_workflow: Indicate whether 2 steps from this process \
should be added to the dictionary assigned to loanpy.adrc.Adrc.workflow \
(useful for debugging): the calculated \
phonotactic profile of the input-string and the predicted repaired structures.
        :type show_workflow: bool, default=False

        :returns: a list of phonotacticly repaired words
        :rtype: list of str

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"input_files"
        >>> path2sc = path2folder / "sc_ad_handmade.txt"
        >>> path2forms = path2folder / "forms_3cogs_wot.csv"
        >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
forms_csv=path2forms, \
source_language="WOT", \
target_language="EAH")
        >>> adrc_obj.repair_phonotactics(ipastr="kiki", \
max_repaired_phonotactics=1)
        [['k', 'i', 'k']]
        >>> adrc_obj.repair_phonotactics(ipastr="kiki", \
max_repaired_phonotactics=2)
        [['k', 'i', 'k'], ['k', 'i', 'C', 'k', 'i']]
        >>> adrc_obj.repair_phonotactics(ipastr="kiki", \
max_repaired_phonotactics=2, \
max_paths2repaired_phonotactics=2)
        >>> #C can get inserted before or after k
        [['k', 'i', 'k'], ['k', 'i', 'C', 'k', 'i'], ['k', 'i', 'k', 'C', 'i']]
        >>> adrc_obj.scdict_phonotactics = {}  # empty sound corresp \
data triggers heuristics
        >>> adrc_obj.repair_phonotactics(ipastr="kiki", \
max_repaired_phonotactics=2, \
show_workflow=True)
        [['V', 'k', 'i', 'k', 'i'], ['i', 'k', 'i', 'C']]
        >>> adrc_obj.workflow
        OrderedDict([('donor_phonotactics', ['CVCV']), \
('predicted_phonotactics', \
[['VCVCV', 'VCVC']])])

        """

        # tokenise if input is string
        if isinstance(ipastr, str):
            ipastr = tokenise(ipastr)
        # get phonotactic profile of input string
        if max_repaired_phonotactics == 0:
            return [ipastr]
        donorstruc = self.word2phonotactics(ipastr)
        # append to workflow if indicated, to check if this went correctly
        if show_workflow:
            self.workflow["donor_phonotactics"] = str(donorstruc)
        # check if there is data available for this structure
        try:
            predicted_phonotactics = self.scdict_phonotactics[
                donorstruc][:max_repaired_phonotactics]
        # if not use heuristics: pick n most similar strucs from inventory
        except KeyError:
            predicted_phonotactics = self.rank_closest_phonotactics(
                donorstruc, max_repaired_phonotactics).split(", ")
        # append this step to workflow for debugging, if indicated
        if show_workflow:
            self.workflow[
                "predicted_phonotactics"] = str(predicted_phonotactics)
        # get edit operations between strucs and apply them to input IPA-string
        return flatten([[apply_edit(ipastr, edop) for edop in
                         editops(
                                 donorstruc,
                                 pred,
                                 max_paths2repaired_phonotactics,
                                 deletion_cost,
                                 insertion_cost)]
                        for pred in predicted_phonotactics])

    def adapt(self,
              ipastr,
              howmany=1,
              cluster_filter=False,
              phonotactics_filter=False,
              repair_vowelharmony=False,
              sort_by_nse=False,
              max_repaired_phonotactics=0,
              max_paths2repaired_phonotactics=1,
              deletion_cost=100,
              insertion_cost=49,
              show_workflow=False):
        """
        Takes a word as input and uses available data \
together with heuristics to make predictions about its transformation \
when entering a target language as a loan.

        :param ipastr: The non-tokenised input word. Should consist only of \
valid IPA-characters, as defined in ipa_all.csv's column "ipa", even though \
the tokeniser handles invalid characters quite well. Make sure this is not \
an empty string.
        :type ipastr: str

        :param howmany: Indicate how many guesses should be made. If all \
predictions are wrong, this is the same as the false positive rate. \
If the right prediction is among the guesses, it is the false positive \
rate plus one.
        :type howmany: int, default=1

        :param cluster_filter: Throws out all words that \
contain vowel or consonant clusters that are not documented in the target \
language.
        :type cluster_filter: bool, default=False

        :param phonotactics_filter: Indicate whether words \
should be filtered out \
from the final result if their phonotactic profile does not occur in the \
phonotactic inventory of target language.
        :type phonotactics_filter: bool, default=False

        :param repair_vowelharmony: Indicate whether violations of \
constraint "front-back vowel harmony" should be repaired.
        :type repair_vowelharmony: bool, default=False

        :param sort_by_nse: Indicate whether results should \
be sorted by their \
likelihood. Can be costly to calculate. If bool is passed, all or no \
words will be sorted. If int is passed, only that many words will be sorted \
in the beginning of the list, the rest remains unsorted.
        :type sort_by_nse: bool, int, default=False

        :param max_repaired_phonotactics: Indicate how many of \
the most similar \
available profiles \
from the phonotactic inventory should be taken into consideration.
        :type max_repaired_phonotactics: int, default=0

        :param max_paths2repaired_phonotactics: Indicate in maximum how many \
different ways \
each phonotactic profile should be repaired towards the same target. E.g. if \
source is "CCV" and target "CV", the first or the second "C" can be \
deleted.
        :type max_paths2repaired_phonotactics: int, default=1

        :param deletion_cost: The cost of deleting a phoneme
        :type deletion_cost: int | float, default=100

        :param insertion_cost: The cost of inserting a phoneme
        :type insertion_cost: int | float, default=49

        :param show_workflow: Indicate if the workflow should be \
documented. Useful for debugging and makes it less black-boxy. \
The single steps are added as keys to the dictionary assigned to \
loanpy.adrc.Adrc.workflow. The \
number of keys varies between 2-5, depending on the arguments \
passed on to this function. \
Keys "tokenised" and "adapted_phonotactics" are always there. \
Keys "donor_phonotactics" \
and "predicted_phonotactics" are only added if param \
<max_repaired_phonotactics> was \
set to greater than 0. Key "adapted_vowelharmony" is only added if \
param <repair_vowelharmony> was set to True.
        :type show_workflow: bool, default=False

        :returns: As many predictions as indicated in param \
 <howmany>, separated by ", "
        :rtype: str

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"input_files"
        >>> path2sc = path2folder / "sc_ad_handmade.txt"
        >>> path2forms = path2folder / "forms_3cogs_wot.csv"
        >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
forms_csv=path2forms, \
source_language="WOT", \
target_language="EAH")
        >>> adrc_obj.adapt(ipastr="dade", howmany=5)
        "dady, datʰy, dedy, detʰy, tʰady"
        >>> # repair phonotactics with data hard-coded in "sc_ad_handmade.txt"
        >>> # Usually this is the same as data extracted from forms.csv
        >>> # But now due to illustrative purposes they are different.
        >>> adrc_obj.adapt(ipastr="dade", howmany=6, \
max_repaired_phonotactics=2)
        "dad, ded, tʰad, tʰed, dajdy, dejdy"
        >>> # max_paths2repaired_phonotactics=2 causes j to be \
inserted before AND after d
        >>> adrc_obj.adapt(ipastr="dade", howmany=6, \
max_repaired_phonotactics=2, \
max_paths2repaired_phonotactics=2)
        "dad, tʰad, dajdy, tʰajdy, dadjy, tʰadjy"
        >>> adrc_obj.vow2fb["e"] = "B"  # let's assume "e" was a backvowel.
        >>> # repair repair_vowelharmony before substituting: dade->dadF
        >>> adrc_obj.adapt(repair_vowelharmony=True, ipastr="dade", \
howmany=6, \
max_repaired_phonotactics=2, max_paths2repaired_phonotactics=2)
        "dad, tʰad, dajdæ, tʰajdæ, dujdy, tʰujdy"
        >>> # phonotactic inventory for phonotactics_filter is calculated \
from forms.csv!
        >>> # contains only structures of the 3 words occurring in \
the target lg EAH
        >>> adrc_obj.phonotactic_inventory  # this will filter out all results
        {'VCVC', 'VCVCV', 'VCCVC'}
        >>> adrc_obj.adapt(phonotactics_filter=True, \
repair_vowelharmony=True, \
ipastr="dade", howmany=6, max_repaired_phonotactics=2, \
max_paths2repaired_phonotactics=2)
        'wrong phonotactics'
        >>> adrc_obj.phonotactic_inventory.add('CVCCV')  \
# so let's assume CVCCV \
was in the inventory
        >>> adrc_obj.adapt(phonotactics_filter=True, \
repair_vowelharmony=True, \
ipastr="dade", howmany=6, max_repaired_phonotactics=2, \
max_paths2repaired_phonotactics=2)
        "dajdæ, tʰajdæ, dujdy, tʰujdy, dadjæ, tʰadjæ"
        >>> # now let's filter out all clusters undocumented in forms.csv
        >>> adrc_obj.cluster_inventory  # only these clusters are allowed
        {'ld', 't͡ʃ', 'j', 'ɣ', 'a', 'n', 'ia'}
        >>> adrc_obj.adapt(cluster_filter=True, phonotactics_filter=True, \
repair_vowelharmony=True, ipastr="dade", howmany=6, \
max_repaired_phonotactics=2, \
max_paths2repaired_phonotactics=2)
        "wrong clusters"
        >>>  # let's use a different sound correspondence file
        >>> path2sc = path2folder / "sc_ad_handmade2.txt"
        >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
forms_csv=path2forms, \
source_language="WOT", \
target_language="EAH")
        >>> adrc_obj.phonotactic_inventory.add('CVCCV')
        >>> # let's ramp up the combinatorics
        >>> adrc_obj.adapt(howmany=1000, cluster_filter=True, \
phonotactics_filter=True, \
repair_vowelharmony=True, ipastr="dade", max_repaired_phonotactics=2, \
max_paths2repaired_phonotactics=2)
        't͡ʃalda'
        >>> adrc_obj.cluster_inventory.add("d")  \
# let's assume d was an allowed cluster
        >>> adrc_obj.adapt(howmany=1000, cluster_filter=True, \
phonotactics_filter=True, repair_vowelharmony=True, ipastr="dade", \
max_repaired_phonotactics=2, max_paths2repaired_phonotactics=2)
        'dalda, t͡ʃalda'
        >>> # now sort results by likelihood (nse) and document workflow
        >>> adrc_obj.adapt(sort_by_nse=True, show_workflow=True, \
howmany=1000, cluster_filter=True, \
phonotactics_filter=True, repair_vowelharmony=True, ipastr="dade", \
max_repaired_phonotactics=2, max_paths2repaired_phonotactics=2)
        't͡ʃalda, dalda'
        >>> adrc_obj.workflow
        OrderedDict([('tokenised', \
[['d', 'a', 'd', 'e']]), ('donor_phonotactics', ['CVCV']), \
('predicted_phonotactics', \
[['CVC', 'CVCCV']]), ('adapted_phonotactics', [[['d', 'a', 'd'], \
['d', 'a', 'C', 'd', 'e'], ['d', 'a', 'd', 'C', 'e']]]), \
('adapted_vowelharmony', \
[[['d', 'a', 'd'], ['d', 'a', 'C', 'd', 'e'], \
  ['d', 'a', 'd', 'C', 'e']]]), \
('before_combinatorics', \
[[[['d', 't͡ʃ'], ['a', 'e'], ['d', 't͡ʃ']], \
[['d', 't͡ʃ'], ['a', 'e'], ['l'], ['d', 't͡ʃ'], ['e', 'a']], \
  [['d', 't͡ʃ'], ['a', 'e'], ['d', 't͡ʃ'], ['l'], ['e', 'a']]]])])

        """
        # distribute howmany so that the product of these three approximates it
        (max_phon, max_repaired_phonotactics,
         max_paths2repaired_phonotactics
         ) = get_howmany(howmany, max_repaired_phonotactics,
                         max_paths2repaired_phonotactics)
        # reset workflow variable, tokenise input (must be untokenised ipa str)
        self.workflow, out = OrderedDict(), tokenise(ipastr)
        # document the tokenisation if indicated
        if show_workflow:
            self.workflow["tokenised"] = str(out)

        # repair the phonotactic structure if indicated
        out = self.repair_phonotactics(
                                      out,
                                      max_repaired_phonotactics,
                                      max_paths2repaired_phonotactics,
                                      deletion_cost,
                                      insertion_cost,
                                      show_workflow)
        # document how structure was repaired if indicated
        if show_workflow:
            self.workflow["adapted_phonotactics"] = str(out)

        if repair_vowelharmony:  # repair vowel harmony if indicated
            out = flatten(map(self.repair_harmony, out))
            # document how repair_vowelharmony was repaired if indicated
            if show_workflow:
                self.workflow["adapted_vowelharmony"] = str(out)

        # read possible sound correspondences for each phoneme
        out = [self.read_sc(ipalist, max_phon) for ipalist in out]

        # document which sound corresp were read, if indicated
        if show_workflow:
            self.workflow["before_combinatorics"] = str(out)

        # combine the sound correspondences to create a list of words (str)
        out = combine_ipalists(out)

        # phonotactics repaired, still: 1 phoneme can correspond to +-1 phoneme
        # structure not in target lg's phonotactic inventory
        if phonotactics_filter:
            out = [i for i in out if self.word2phonotactics(i)
                   in self.phonotactic_inventory]
            #  indicate empty filter and return if necessary
            if out == []:
                return "wrong phonotactics"

        # filter clusters not in target lg's cluster inventory
        if cluster_filter:
            out = [wrd for wrd in out
                   if all(cl in self.cluster_inventory for cl
                          in clusterise(wrd))]
            # indicate empty filter and return if necessary
            if out == []:
                return "wrong clusters"

        if sort_by_nse:  # sort resutls by likelyhood (nse) if indicated
            out_nse = [(i, self.get_nse(ipastr, i)) for i in out]  # get nse
            out = pick_minmax(out_nse, sort_by_nse, max, True)

        return ", ".join(out[:howmany])  # cut off leftover, turn to string

    def get_nse(self, left, right):
        """
        Called by loanpy.adrc.Adrc.adapt, loanpy.adrc.Adrc.reconstruct, \
loanpy.loanfinder.Search, loanpy.loanfinder.likeliestphonmatch. \
Aligns two words (alignment type depends \
on the mode defined when initiating \
loanpy.adrc.Adrc), check in the sound correspondence \
dictionary how often each aligned sound correspondence \
occurred (0 if not in dict), sum up their number, and \
divide it by the number of phoneme (clusters) in the word.

        :param left: The string on the left side of the etymology to align.
        :type left: str

        :param right: The string on the right side of the etymology to align.
        :type right: str

        :returns: A tuple of four elements: First is the sum of examples \
        divided by the number of phoneme \
        (clusters) in the word, second is the sum \
        of examples, i.e. how many other words in the etymological data go \
        through the same sound substitution/ sound change as this word. \
        Third is the distribution of sound correspondences, i.e. how many \
        examples in other words are found for each phoneme in the data. \
        Fourth is how the source and target word were aligned. Elements \
        three and four need to be strings, since if they were lists, it would \
        be difficult to build a data frame from them in sanity.py.
        :rtype: (float, int, str, str)

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"input_files"
        >>> path2sc = path2folder / "sc_ad_handmade.txt"
        >>> path2forms = path2folder / "forms_3cogs_wot.csv"
        >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
forms_csv=path2forms, \
source_language="WOT", \
target_language="EAH")
        >>> adrc_obj.get_nse("dade", "dady")
        (33.25, 133, '[1, 6, 1, 125]', "['d<d', 'a<a', 'd<d', 'e<y']")
        """
        # self.align can't handle empty strings as input!
        if not left or not right:
            return (0, 0, [0], [])
        # align the two input strings
        dfsc = self.align(left, right)
        # turn alignment-df into one pandas Series of sound correspondences
        sc = dfsc["vals"] + self.connector + dfsc["keys"] if self.mode == "\
adapt" else (dfsc["keys"] + self.connector + dfsc["vals"])
        # read nr of examples for each sound corresp in sum-of-examples-dict
        outlist = [self.sedict.get(i, 0) for i in sc]
        # add up the nr of examples for each corresp in the word
        outsum = sum(outlist)
        # divide the sum through the length of the word, round on 2 decimals
        normalised_outsum = round(outsum / len(dfsc), 2)
        # add the in-between-steps if indicated so (useful for debugging)
        return normalised_outsum, outsum, str(outlist), str(list(sc))
