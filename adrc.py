"""
Adapt or reconstruct words, i.e. surf horizontally and vertically \
through the network of life
"""

from ast import literal_eval
from collections import Counter, OrderedDict
from itertools import count, cycle, product
from math import prod
from operator import itemgetter

from tqdm import tqdm

from loanpy.helpers import (
Etym,
apply_edit,
clusterise,
combine_ipalists,
editops,
flatten,
get_howmany,
list2regex,
tokenise)
from loanpy.qfysc import Qfy

def read_scdictlist(scdictlist):
    """
    Called by loanpy.adrc.Adrc.__init__. \
Reads sound correspondence dictionary list generated by \
loanpy.qfysc.Qfy.get_sound_corresp from a file.

    :param scdictlist: The path to the sound correspondence dictionaries
    :type scdictlist: pathlib.PosixPath | str | None

    :returns: Only the first 4 of the 6 dicts because the last two are \
not used in any computations at the moment. Returns 4 times None if \
input is None.
    :rtype: [None, None, None, None] | [dict, dict, dict, dict]

    :Example:

    >>> from loanpy.adrc import read_scdictlist, __file__
    >>> from pathlib import Path
    >>> read_scdictlist(None)
    [None, None, None, None]
    >>> path2sc = Path(__file__).parent / "tests" / "integration" \
/ "input_files" / "sc_ad_3cogs.txt"
    >>> read_scdictlist(path2sc)
    [{'a': ['a'], 'd': ['d'], 'j': ['j'], 'l': ['l'], 'n': ['n'], \
't͡ʃː': ['t͡ʃ'], 'ɣ': ['ɣ'], 'ɯ': ['i']}, {'a<a': 6, 'd<d': 1, 'i<ɯ': 1, \
'j<j': 1, 'l<l': 1, 'n<n': 1, 't͡ʃ<t͡ʃː': 1, 'ɣ<ɣ': 2}, {'a<a': [1, 2, 3], \
'd<d': [2], 'i<ɯ': [1], 'j<j': [3], 'l<l': [2], 'n<n': [3], 't͡ʃ<t͡ʃː': [1], \
'ɣ<ɣ': [1, 2]}, \
{'VCCVC': ['VCCVC'], 'VCVC': ['VCVC'], 'VCVCV': ['VCVCV']}]

    """
    if scdictlist is None: return [None]*4
    with open(scdictlist, "r", encoding="utf-8") as f:
        return literal_eval(f.read())[:4]

def move_sc(sclistlist, whichsound, out):
    """
    Called by loanpy.adrc.Adrc.read_sc. \
    Moves sound correspondences. \
A list of stacks where param <whichsound> indicates \
which stack to pick. Append its second element to out and pop its first.

    :param sclistlist: A word where every phoneme has been replaced with a \
list of ALL possible sound correspondences ranked by likelihood, \
i.e. how often \
each sound correspondence occured in the data. \
(Heuristic correspondences have frequency 0.)
    :type sclistlist: list of lists

    :param whichsound: The index of the phoneme to move from sclistlist to \
the output
    :type whichsound: index

    :param out: The future output of loanpy.adrc.Adrc.adapt/reconstruct
    :type out: list of lists

    :returns: List with the selected stack popped, and the new out variable.
    :rtype: tuple: (list of lists, list of lists)

    :Example:

    >>> from loanpy.adrc import move_sc
    >>>  # Transfer phoneme #1 of list #0 from sclistlist to out
    >>> move_sc(sclistlist=[["x", "x"]], whichsound=0, out=[[]])
    ([["x"]], [["x"]])
    >>>  # Transfer phoneme #1 of list #0 from sclistlist to out
    move_sc(sclistlist=[["x", "x"], ["y", "y"], ["z"]], whichsound=0, \
out=[["a"], ["b"], ["c"]])
    ([["x"], ["y", "y"], ["z"]], [["a", "x"], ["b"], ["c"]])
    >>>  # Transfer phoneme #1 of list #2 from sclistlist to out
    >>> move_sc(sclistlist=[["", "$"], ["", "$"], ["Z", "2", "$"]], \
whichsound=2, out=[["o"], ["r"], ["f"]])
    [["", "$"], ["", "$"], ["2", "$"]], [["o"], ["r"], ["f", "2"]])
    """

    out[whichsound].append(sclistlist[whichsound][1]) # move sound #1 to out
    sclistlist[whichsound].pop(0)  # move input by 1 (remove sound #0)
    return sclistlist, out  # tuple

class Adrc(Qfy):
    """
    Read etymological data and information about it generated by loanpy.\
qfysc.py and use it to predict loanword adaptations (lateral transfers) \
and reconstructions (vertical transfers).

    The first 9 parameters are passed on to loanpy.qfysc.Qfy to inherit \
11 attributes (of which 7 are inherited from loanpy.helpers.Etym). The last \
parameter is passed on to __init__ to create 5 own attributes, \
so 16 attributes \
in total

    Define own attributes:

    :param scdictlist: Path to data generated with \
loanpy.qfysc.Qfy.get_sound_corresp. (\
Dicts 0, 1, 2 capture phonological \
correspondences, dicts 3, 4, 5 phonotactical ones. dict0/dict3: the actual \
correspondences, dict1/dict4: How often each correspondence \
occurs in the data, \
dict2/dict5: list of cognates in which each correspondence occurs.
    :type scdictlist: pathlib.PosixPath | str | None

    :Exmaple:

    >>> from loanpy.adrc import Adrc, __file__
    >>> from pathlib import Path
    >>> path2folder = Path(__file__).parent / "tests" / "integration" \
/ "input_files"
    >>> path2sc = path2folder / "sc_ad_3cogs.txt"
    >>> path2forms = path2folder / "forms_3cogs_wot.csv"
    >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
formscsv=path2forms, \
srclg="WOT", tgtlg="EAH", \
mode="reconstruct", \
struc_most_frequent=2)
    >>> adrc_obj.scdict  # sound correspondence dictionary
    {'a': ['a'], 'd': ['d'], 'j': ['j'], 'l': ['l'], 'n': ['n'], \
't͡ʃː': ['t͡ʃ'], 'ɣ': ['ɣ'], 'ɯ': ['i']}
    >>> adrc_obj.sedict  # sum of examples dictionary
    {'a<a': 6, 'd<d': 1, 'i<ɯ': 1, 'j<j': 1, 'l<l': 1, \
'n<n': 1, 't͡ʃ<t͡ʃː': 1, 'ɣ<ɣ': 2}
    >>> adrc_obj.edict  # examples dictionary
    {'a<a': [1, 2, 3], 'd<d': [2], 'i<ɯ': [1], 'j<j': [3], \
'l<l': [2], 'n<n': [3], 't͡ʃ<t͡ʃː': [1], 'ɣ<ɣ': [1, 2]}
    >>> adrc_obj.scdict_struc  # phonotactic correspondence dictionary
    {'VCCVC': ['VCCVC'], 'VCVC': ['VCVC'], 'VCVCV': ['VCVCV']}
    >>> adrc_obj.workflow
    OrderedDict()
    >>> len(adrc_obj.__dict__)  # 5 own + 11 attributes inherited \
from loanpy.qfysc.Qfy
    16

    """
    def __init__(self,
    # 9 args for inheritance from from loanpy.qfysc.Qfy
    formscsv=None,
    srclg=None,
    tgtlg=None,
    struc_most_frequent=9999999,
    struc_inv=None,
    mode=None,
    connector=None,
    scdictbase=None,
    vfb=None,
    # only this will be read here.
    scdictlist=None):
        # inherit from loanpy.qfysc.Qfy
        super().__init__(
        formscsv=formscsv,
        srclg=srclg,
        tgtlg=tgtlg,
        struc_most_frequent=struc_most_frequent,
        struc_inv=struc_inv,
        mode=mode,
        connector=connector,
        scdictbase=scdictbase,
        vfb=vfb)
        # read here - was extracted by loanpy.qfysc.Qfy and written to file
        (self.scdict, self.sedict, self.edict, self.scdict_struc
        ) = read_scdictlist(scdictlist)  # sound correspondence dictionaries

        self.workflow = OrderedDict()  # will be filled by self.adapt()

    def get_diff(self, sclistlist, ipa):
        """
        Called by loanpy.adrc.Adrc.read_sc. \
Tells how much it would cost to move each sound correspondence \
by looking up the number of occurences of the current and the next phoneme \
in the sum-of-example dictionary and subtracting the latter from the former. \
(They were sorted by decreasing frequency by \
loanpy.qfysc.Qfy.get_sound_corresp) \
The bigger the difference the greater the cost to move it. \
Since the higher the sum \
of examples for each phoneme in a word, the more credible its etymology.

    :param sclistlist: A word where every phoneme has been replaced with a \
list of possible sound correspondences ranked by likelihood, i.e. how often \
each sound correspondence occured in the data.
    :type sclistlist: list of lists

    :param ipa: The tokenised/clusterised input string
    :type ipa: list

    :returns: A list of integers where the integers indicate the cost of \
moving the phoneme that is at the same index in the sound correspondence list.
    :rtype: list of int

    :Example:

    >>> from loanpy.adrc import Adrc, __file__
    >>> from pathlib import Path
    >>> path2folder = Path(__file__).parent / "tests" / "integration" \
/ "input_files"
    >>> path2sc = path2folder / "sc_ad_3cogs.txt"
    >>> path2forms = path2folder / "forms_3cogs_wot.csv"
    >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
formscsv=path2forms, \
srclg="WOT", tgtlg="EAH")
    >>> adrc_obj.get_diff(sclistlist=[["d", "x", "$"], ["a", "x", "$"], \
["d", "x", "$"], ["a", "x", "$"]], ipa=["d", "a", "d", "a"])
    [1, 6, 1, 6]
        """
        # difference in nr of examples between current and next sound corresp
        # for each phoneme or cluster in a word
        difflist = []  # this will be returned
        # loop through phonemes/clusters of word
        for idx, sclist in enumerate(sclistlist):
            # get nr of occurences of current sound corresp (0 if not in dict)
            firstsc = self.sedict.get(ipa[idx] + self.connector + sclist[0], 0)
            # check for two exceptions:
            if len(sclist) == 2: # exception 1: if list has reached the end...
                # ... it can never be moved again. Bc nth bigger than inf.
                difflist.append(float("inf"))  # = stop button
                continue  # check next phoneme
            # exception 2: no data avail. ~ nr of occurences == 0 ~ heuristics
            # don't loop through heuristics before all data available used
            if firstsc == 0:
                difflist.append(9999999) # = pause/freeze button...
                continue  # ... can be unfrozen by inf (= end of list)

            # get nr of occurences of next sound corresp (0 if no data avail.)
            nextsc = self.sedict.get(ipa[idx] + self.connector + sclist[1], 0)
            # append diffrnc between current & next sound corresp to outputlist
            difflist.append(firstsc - nextsc)

        return difflist

    def read_sc(self, ipa, howmany=1):
        """
        Called by loanpy.adrc.Adrc.adapt and loanpy.adrc.Adrc.reconstruct. \
Replaces every phoneme of a word with a list of phonemes \
that it can correspond \
to, meeting following conditions: a. The product of the length of each list \
is just minimally above the number indicated in \
param <howmany> (leftover will \
be sliced away later). b. Those phonemes are chosen that diminsh the sum of \
examples of the predicted word the least. (Sum of example means \
adding together how many times \
each phoneme of the predicted reconstruction corresponded \
to the aligned phoneme of the source word in the etymological data.)

        :param ipa: a tokenised/clusterised word
        :type ipa: list

        :param howmany: Howmany words would this be, if combinatorics were \
applied. This is the false positive rate if the prediction is wrong but \
the false positive rate -1 if the prediction is right. (Say I make \
1 guess and its correct, then there are 0 false positives, i.e. howmany-1. \
If I make one guess and it's wrong then I'll have 1 false positive.)
        :type howmany: int, default=1

        :returns: The information to which sounds each input \
sound can correspond.
        :rtype: list of lists

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"integration" / "input_files"
        >>> path2sc = path2folder / "sc_ad_handmade.txt"
        >>> adrc_obj = Adrc(scdictlist=path2sc)
        >>> adrc_obj.read_sc(ipa="dade", howmany=1)  # 1*1*1*1 = 1
        [["d"], ["a"], ["d"], ["y"]]
        >>> adrc_obj.read_sc(ipa="dade", howmany=4)  # 2*2*1*1 = 4
        [["d", "tʰ"], ["a", "e"], ["d"], ["y"]]
        >>> adrc_obj.read_sc(ipa="dade", howmany=160)  # 4*5*4*2 = 160
        [["d", "tʰ", "t", "tː"], \
["a", "e", "i", "o", "u"], ["d", "tʰ", "t", "tː"], ["y", "u"]]
        >>> adrc_obj.read_sc(ipa="dade", howmany=float("inf"))  # all possible
        [["d", "tʰ", "t", "tː"], \
["a", "e", "i", "o", "u"], ["d", "tʰ", "t", "tː"], ["y", "u", "e"]]
        """

        # grab all sound correspondences from dictionary
        sclistlist = [self.scdict[i] for i in ipa]
        # if howmany is bigger/equal than their product, return all of them.
        if howmany >= prod([len(scl) for scl in sclistlist]): return sclistlist
        # else add a stop sign to the end of each sound corresp list
        sclistlist = [sclist+["$"] for sclist in sclistlist]
        # grab only 1st (=most likely/frequent) sound corresp for each phoneme
        out = [[i[0]] for i in sclistlist]
        # decide which sound corresp to accept next. Stop if product reached
        while howmany > prod([len(scl) for scl in out]):
            # get by how much each new sound corresp would diminish the nse
            difflist = self.get_diff(sclistlist, ipa)  # e.g. [0, 0, 1, 2]
            minimum = min(difflist)  # how much is lowest possible difference?
            # get list index for all phonemes making the least difference.
            indices = [i for i, v in enumerate(difflist) if v == minimum]
            if len(indices) == 1:  # if only 1 element makes least difference
                sclistlist, out = move_sc(sclistlist, indices[0], out)  # Use!
                continue # jump up to while and check if product is reached
            # but if multiple elements are the minimum...
            difflist2 = difflist  #...remember the differences they make, ...
            idxpool = cycle(indices)  # ... and cycle through them...
            while (difflist2 == difflist  # ... until differences change, or:
                   and howmany > prod([len(scl) for scl in out])):  # ">" (!)
                # grab next sound correspondence
                sclistlist, out = move_sc(sclistlist, next(idxpool), out)
                # check the differences all phonemes would make
                difflist2 = self.get_diff(sclistlist, ipa)
                # latest if a sound hits end of list: turns 2 inf, breaks loop

        return out

    def reconstruct(self, ipastring, howmany=1, clusterised=True,
                    struc=False, vowelharmony=False, sort_by_nse=False):
        """
        Predicts past forms of a word based on data. Should \
theoretically also work for forward reconstructions, but not tested yet. \
Every word gets a "#-" and a "-#" slapped to its front and back, to capture \
prefixes and suffixes that may have appeared or disappeared. In addition to \
this, word initial and word final sounds/clusters are \
tagged with an extra "#". \
If parameters <struc>, <vowelharmony> and <sort_by_nse> are all set to False, \
the output will be a regular expression of the type "^(a|b)(c|d)(e)$". If one \
of those parameters is set to True, combinatorics will be applied and the \
outputted regular expression will be of the type "(^ace$|^ade$|^bce$|^bde$)".

        :param ipastring: The non-tokenised input word. \
Should consist only of \
valid ipa-characters, as defined in ipa_all.csv's column "ipa", even though \
the tokeniser handles invalid characters quite well. Make sure this is not \
an empty string.
        :type ipastring: str

        :param howmany: Indicate howmany guesses should be made.
        :type howmany: int, default=1

        :param clusterised: If set to True, this will slice up the input \
word into consonant and vowel clusters and look for those keys in the sound \
change dictionary.
        :type clusterised: bool, default=True

        :param struc: Indicate whether words should be filtered out \
from the final result if their phonotactic profile does not occur in the \
phonotactic inventory of target language.
        :type struc: bool, default=False

        :param vowelharmony: Indicate whether words violating the \
constraint front-back vowelharmony (a word can contain only front or only \
back vowels) should be filtered.
        :type vowelharmony: bool, default=False

        :param sort_by_nse: Indicate whether results \
should be sorted by their \
normalised sum of examples (likelihood measure for etymologies). \
Can be costly to calculate but still cheaper and more elegant than \
replacing itertool's product function, which does this (from its \
documentation): "The leftmost iterators are in the \
outermost for-loop, so the \
output tuples cycle in a manner similar to an odometer \
(with the rightmost element changing on every iteration)" \

        :type sort_by_nse: bool, default=False

        :returns: A regular expression approximating \
the indicated number of predicted reconstructions
        :rtype: str

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"integration" / "input_files"
        >>> path2sc = path2folder / "sc_rc_3cogs.txt"
        >>> adrc_obj = Adrc(scdictlist=path2sc, mode="reconstruct")
        >>> adrc_obj.reconstruct("kriekrie")  # clusterise, missing from data
        '#kr, ie, kr, ie# not old'
        >>> adrc_obj.reconstruct("kriekrie", clusterised=False)  # tokenise
        '#k, i, e, k, i, e# not old'
        >>> adrc_obj.reconstruct("aːruː")
        '^(a)(n)(a)(at͡ʃi)$'
        >>> adrc_obj.reconstruct("aːruː", howmany=2)
        '^(a)(n)(a)(at͡ʃi|ɣ)$'
        >>> path2forms = path2folder / "forms_3cogs_wot.csv"
        >>> # read etymological data to get phonotactic inventory for filter
        >>> adrc_obj = Adrc(formscsv=path2forms, srclg="H", \
tgtlg="EAH", scdictlist=path2sc, mode="reconstruct")
        >>> adrc_obj.reconstruct("aːruː", howmany=2, struc=True)  \
# only CVCV in inventory
        '^anaɣ$'
        >>> adrc_obj.reconstruct("aːruː", howmany=1, struc=True)  \
# low howmany -> empty filter
        'wrong phonotactics'
        >>> adrc_obj.vow2fb["i"] = "B"  # let's assume "i" was a back vowel
        >>> adrc_obj.reconstruct("aːruː", howmany=4, vowelharmony=True)
        '^anaɣ$'
        >>> # "anaat͡ʃi" got filtered out b/c it contains \
a front and back vowel
        >>> # violation of constraint "vowelharmony" in \
terms of optimality theory
        >>> adrc_obj.reconstruct("aːruː", howmany=1, vowelharmony=True)  \
# low howmany -> empty filter
        'wrong vowel harmony'
        >>> adrc_obj.vow2fb["i"] = "F"  # make "i" a front vowel again
        >>> adrc_obj.reconstruct("aːruː", howmany=4, vowelharmony=True)  \
# nothing gets filtered
        "^anaat͡ʃi$|^anaɣ$"
        >>> adrc_obj.reconstruct("aːruː", howmany=4, sort_by_nse=True)
        >>> # examples per phoneme divided by word length is higher for "anaɣ"
        "^anaɣ$|^anaat͡ʃi$"
        """

        # slice up the input the way it's indicated in param <clusterised>
        ipalist = clusterise(ipastring) if clusterised else tokenise(ipastring)

        # apply same tagging process as in loanpy.qfysc.Qfy.align_clusterwise
        ipalist[0], ipalist[-1] = f"#{ipalist[0]}", f"{ipalist[-1]}#"
        ipalist = ["#-"] + ipalist + ["-#"]

        # if phonemes missing from sound correspondence dict, return which ones
        if not all(phon in self.scdict for phon in ipalist): return ', '.join(
        [i for i in ipalist if i not in self.scdict]) + " not old"

        # read the correct number of sound correspondences per phoneme
        out = self.read_sc(ipalist, howmany)

        # skip combinatorics, instead return result if these 3 params are False
        if all(i is False for i in [struc, vowelharmony, sort_by_nse]):
            return f"^{''.join([list2regex(i) for i in out])}$"

        # if one of the 3 params is True however, apply combinatorics
        out = ["".join(i).replace("-", "") for i in product(*out)]

        # apply first filter if indicated (wrong phontactics out)
        if struc is True:
            out = [i for i in out if self.word2struc(i) in self.struc_inv]
            if out == []: return "wrong phonotactics"

        # apply 2nd filter if indicated (wrong vowelharmony out)
        if vowelharmony is True:
            out = [i for i in out if self.harmony(i)]
            if out == []: return "wrong vowel harmony"

        # sort results by decreasing likelihood (normalised sum of examples)
        if sort_by_nse is True:
            nse = map(lambda x: self.get_nse(ipastring, x), out)
            out = [i[1] for i in sorted(zip(nse, out), reverse=True)]

        # can't have float in slice, but howmany=float("inf") is possible now
        if howmany != float("inf"): out = out[:howmany]
        return f"^{'$|^'.join(out)}$"  # turn list to regular expression

    def adapt_struc(self, ipa_in, max_struc=2, max_paths=1,
    deletion_cost=100, insertion_cost=49, show_workflow=False):
        """
        Called by loanpy.adrc.Adrc.adapt. \
Repairs the phonotactic structure of a word.

        :pararm ipa_in: The input word. Will be tokenised if string.
        :type ipa_in: list | str

        :param max_struc: The maximum number of target phonotactic structures \
into which we want to turn the source structure.
        :type max_struc: int, default=2

        :param max_paths: The maximum number of different cheapest ways to \
turn the source structure into the target structure
        :type max_paths: int, default=1

        :param deletion_cost: The cost of deleting a segment
        :type deletion_cost: int, float, default=100

        :param insertion_cost: The cost of inserting a segment
        :type insertion_cost: int, float, default=49

        :param show_workflow: Indicate whether 2 steps from this process \
should be added to self.workflow (useful for debugging): the calculated \
phonotactic profile of the input-string and the predicted repaired structures.
        :type show_workflow: bool, default=False

        :returns: a list of phonotactically repaired words
        :rtype: list of str

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"integration" / "input_files"
        >>> path2sc = path2folder / "sc_ad_handmade.txt"
        >>> path2forms = path2folder / "forms_3cogs_wot.csv"
        >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
formscsv=path2forms, \
srclg="WOT", \
tgtlg="EAH")
        >>> adrc_obj.adapt_struc(ipa_in="kiki", max_struc=1)
        [['k', 'i', 'k', 'i']]
        >>> adrc_obj.adapt_struc(ipa_in="kiki", max_struc=2)
        [['k', 'i', 'k'], ['k', 'i', 'C', 'k', 'i']]
        >>> adrc_obj.adapt_struc(ipa_in="kiki", max_struc=2, max_paths=2)
        >>> #C can get inserted before or after k
        [['k', 'i', 'k'], ['k', 'i', 'C', 'k', 'i'], ['k', 'i', 'k', 'C', 'i']]
        >>> adrc_obj.scdict_struc = {}  # empty sound corresp \
data triggers heuristics
        >>> adrc_obj.adapt_struc(ipa_in="kiki", max_struc=2, \
show_workflow=True)
        [['V', 'k', 'i', 'k', 'i'], ['i', 'k', 'i', 'C']]
        >>> adrc_obj.workflow
        OrderedDict([('donor_struc', ['CVCV']), ('pred_strucs', \
[['VCVCV', 'VCVC']])])

        """

        # tokenise if input is string
        if isinstance(ipa_in, str): ipa_in = tokenise(ipa_in)
        # if only 1 guess the safest is: the struture stays the same
        if max_struc == 1: return [ipa_in]
        # get phonotactic profile of input string
        donorstruc = self.word2struc(ipa_in)
        # append to workflow if indicated, to check if this went correctly
        if show_workflow: self.workflow["donor_struc"] = str(donorstruc)
        # check if there is data available for this structure
        try: pred_strucs = self.scdict_struc[donorstruc][:max_struc]
        # if not use heuristics: pick n most similar strucs from inventory
        except KeyError: pred_strucs = self.rank_closest_struc(donorstruc,
        max_struc).split(", ")
        # append this step to workflow for debugging, if indicated
        if show_workflow: self.workflow["pred_strucs"] = str(pred_strucs)
        # get edit operations between strucs and apply them to input ipa-string
        return flatten([[apply_edit(ipa_in, edop) for edop in
        editops(donorstruc, pred, max_paths, deletion_cost, insertion_cost)
        ] for pred in pred_strucs])

    def adapt(self,
    ipa_in,
    howmany=1,
    max_struc=1,
    max_paths=1,
    deletion_cost=100,
    insertion_cost=49,
    vowelharmony=False,
    clusterised=False,
    sort_by_nse=False,
    struc_filter=False,
    show_workflow=False):
        """
        Takes a word as input and makes predictions based on available data \
and heuristics how it could be repaired when entering target \
language as a loan.

        :param ipa_in: The non-tokenised input word. Should consist only of \
valid ipa-characters, as defined in ipa_all.csv's column "ipa", even though \
the tokeniser handles invalid characters quite well. Make sure this is not \
an empty string.
        :type ipa_in: str

        :param howmany: Indicate howmany guesses should be made.
        :type howmany: int, default=1

        :param max_struc: Indicate howmany of the most similar \
available structures \
from the phonotactic inventory should be taken into consideration.
        :type max_struc: int, default=1

        :param max_paths: Indicate in maximum howmany different ways \
each phonotactic structure should be repaired.
        :type max_paths: int, default=1

        :param deletion_cost: The cost of deleting a phoneme
        :type deletion_cost: int | float, default=100

        :param insertion_cost: The cost of inserting a phoneme
        :type insertion_cost: int | float, default=49

        :param vowelharmony: Indicate whether violations of front-back \
vowelharmony should be repaired.
        :type vowelharmony: bool, default=False

        :param clusterised: This is a filter. It throws out all words that \
contain vowel or consonant clusters that are not documented in the target \
language.
        :type clusterised: bool, default=False

        :param sort_by_nse: Indicate whether results should \
be sorted by their \
likelihood. Can be costly to calculate.
        :type sort_by_nse: bool, default=False

        :param struc_filter: Indicate whether words should be filtered out \
from the final result if their phonotactic profile does not occur in the \
phonotactic inventory of target language.
        :type struc_filter: bool, default=False

        :param show_workflow: Indicate if the workflow should be attached \
to the output. Useful for debugging and makes it less black-boxy.
        :type show_workflow: bool, default=False

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"integration" / "input_files"
        >>> path2sc = path2folder / "sc_ad_handmade.txt"
        >>> path2forms = path2folder / "forms_3cogs_wot.csv"
        >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
formscsv=path2forms, \
srclg="WOT", \
tgtlg="EAH")
        >>> adrc_obj.adapt(ipa_in="dade", howmany=5)
        "dady, datʰy, dedy, detʰy, tʰady"
        >>> # repair phonotactics with data hard-coded in "sc_ad_handmade.txt"
        >>> # Usually this is the same as data extracted from forms.csv
        >>> # But now due to illustrative purposes they are different.
        >>> adrc_obj.adapt(ipa_in="dade", howmany=6, max_struc=2)
        "dad, ded, tʰad, tʰed, dajdy, dejdy"
        >>> # max_paths=2 causes j to be inserted before AND after d
        >>> adrc_obj.adapt(ipa_in="dade", howmany=6, max_struc=2, max_paths=2)
        "dad, tʰad, dajdy, tʰajdy, dadjy, tʰadjy"
        >>> adrc_obj.vow2fb["e"] = "B"  # let's assume "e" was a backvowel.
        >>> # repair vowelharmony before substituting: dade->dadF
        >>> adrc_obj.adapt(vowelharmony=True, ipa_in="dade", howmany=6, \
max_struc=2, max_paths=2)
        "dad, tʰad, dajdæ, tʰajdæ, dujdy, tʰujdy"
        >>> # phonotactic inventory for struc_filter is calculated \
from forms.csv!
        >>> # contains only structures of the 3 words occuring in \
the target lg EAH
        >>> adrc_obj.struc_inv  # this will filter out all results
        {'VCVC', 'VCVCV', 'VCCVC'}
        >>> adrc_obj.adapt(struc_filter=True, vowelharmony=True, \
ipa_in="dade", howmany=6, max_struc=2, max_paths=2)
        'wrong phonotactics'
        >>> adrc_obj.struc_inv.add('CVCCV')  # so let's assume CVCCV \
was in the inventory
        >>> adrc_obj.adapt(struc_filter=True, vowelharmony=True, \
ipa_in="dade", howmany=6, max_struc=2, max_paths=2)
        "dajdæ, tʰajdæ, dujdy, tʰujdy, dadjæ, tʰadjæ"
        >>> # now let's filter out all clusters undocumented in forms.csv
        >>> adrc_obj.clusters  # only these clusters are allowed
        {'ld', 't͡ʃ', 'j', 'ɣ', 'a', 'n', 'ia'}
        >>> adrc_obj.adapt(clusterised=True, struc_filter=True, \
vowelharmony=True, ipa_in="dade", howmany=6, max_struc=2, max_paths=2)
        "wrong clusters"
        >>>  # let's use a different sound correspondence file
        >>> path2sc = path2folder / "sc_ad_handmade2.txt"
        >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
formscsv=path2forms, \
srclg="WOT", \
tgtlg="EAH")
        >>> adrc_obj.struc_inv.add('CVCCV')
        >>> # let's ramp up the combinatorics
        >>> adrc_obj.adapt(howmany=1000, clusterised=True, struc_filter=True, \
vowelharmony=True, ipa_in="dade", max_struc=2, max_paths=2)
        't͡ʃalda'
        >>> adrc_obj.clusters.add("d")  # let's assume d was an allowed cluster
        >>> adrc_obj.adapt(howmany=1000, clusterised=True, \
struc_filter=True, vowelharmony=True, ipa_in="dade", max_struc=2, max_paths=2)
        'dalda, t͡ʃalda'
        >>> # now sort results by likelihood (nse) and document workflow
        >>> adrc_obj.adapt(sort_by_nse=True, show_workflow=True, \
howmany=1000, clusterised=True, \
struc_filter=True, vowelharmony=True, ipa_in="dade", max_struc=2, max_paths=2)
        't͡ʃalda, dalda'
        >>> adrc_obj.workflow
        OrderedDict([('tokenised', \
[['d', 'a', 'd', 'e']]), ('donor_struc', ['CVCV']), ('pred_strucs', \
[['CVC', 'CVCCV']]), ('adapted_struc', [[['d', 'a', 'd'], \
['d', 'a', 'C', 'd', 'e'], ['d', 'a', 'd', 'C', 'e']]]), \
('adapted_vowelharmony', \
[[['d', 'a', 'd'], ['d', 'a', 'C', 'd', 'e'], \
  ['d', 'a', 'd', 'C', 'e']]]), \
('before_combinatorics', \
[[[['d', 't͡ʃ'], ['a', 'e'], ['d', 't͡ʃ']], \
[['d', 't͡ʃ'], ['a', 'e'], ['l'], ['d', 't͡ʃ'], ['e', 'a']], \
  [['d', 't͡ʃ'], ['a', 'e'], ['d', 't͡ʃ'], ['l'], ['e', 'a']]]])])

        """
        # distribute howmany so that the product of these three approximates it
        max_phon, max_struc, max_paths = get_howmany(
        howmany, max_struc, max_paths)
        # reset workflow variable, tokenise input (must be untokenised ipa str)
        self.workflow, out = OrderedDict(), tokenise(ipa_in)
        # document the tokenisation if indicated
        if show_workflow: self.workflow["tokenised"] = str(out)

        # repair the phonotactic structure. With max_struc=1 nothing happens
        out = self.adapt_struc(out,
        max_struc, max_paths, deletion_cost, insertion_cost, show_workflow)
        # document how structure was repaired if indicated
        if show_workflow: self.workflow["adapted_struc"] = str(out)

        if vowelharmony:  # repair vowel harmony if indicated
            out = flatten(map(self.adapt_harmony, out))
            # document how vowelharmony was repaired if indicated
            if show_workflow: self.workflow["adapted_vowelharmony"] = str(out)

        # read possible sound correspondences for each phoneme
        out = [self.read_sc(ipalist, max_phon) for ipalist in out]

        # document which sound corresp were read, if indicated
        if show_workflow: self.workflow["before_combinatorics"] = str(out)

        # combine the sound correspondences to create a list of words (str)
        out = combine_ipalists(out)

        # phonotactics repaired, still: 1 phoneme can correspond to +-1 phoneme
        if struc_filter:  # structure not in target lg's phonotactic inventory
            out = [i for i in out if self.word2struc(i) in self.struc_inv]
            #  indicate empty filter and return if necessary
            if out == []: return "wrong phonotactics"

        if clusterised:  # filter clusters not in target lg's cluster inventory
            out = [wrd for wrd in out
                   if all(cl in self.clusters for cl in clusterise(wrd))]
            # indicate empty filter and return if necessary
            if out == []: return "wrong clusters"

        if sort_by_nse:  # sort resutls by likelyhood (nse) if indicated
            out = [(self.get_nse(ipa_in, i), i) for i in out]  # get nse
            out.sort(key=itemgetter(0), reverse=True)  # sort by it
            out = [i[1] for i in out]  # discard nse, keep results

        return ", ".join(out[:howmany])  # cut off leftover, turn to string

    def get_nse(self, left, right, show_workflow=False):
        """
        Called by loanpy.adrc.Adrc.adapt, loanpy.adrc.Adrc.reconstruct, \
loanpy.loanfinder.Search, loanpy.loanfinder.likeliestphonmatch. \
Returns 0 if one of the sound correspondences is not documented \
in the sound correspondence dictionary. \
By default we are calculating the nse: Check in the sound correspondence \
dictionary how often each sound correspondence occured, add them together, \
divide by number of phonemes in the word. If show_workflow is set to True, \
a tuple will be returned with (normalised sum of examples, sum of examples, \
list of number of examples for each phoneme). If se=False, instead of \
the number of examples, the list of cognate sets in which each sound \
correspondence \
occurs will be accessed. The return value then is a list of lists. \
show_workflow does not do anything if se=False.

        :param left: The string on the left side of the etymology to align.
        :type left: str

        :param right: The string on the right side of the etymology to align.
        :type right: str

        :param se: Calculations based on sum-of-examples dict. \
If set to False, \
examples dict will be accessed instead to add extra info \
but make no calculations.
        :type se: bool, default=True

        :param show_workflow: If set to True, this \
will output how the nse was \
calculated.
        :type show_workflow: bool, default=False

        :returns: int | list of int | tuple | list of list

        :Example:

        >>> from loanpy.adrc import Adrc, __file__
        >>> from pathlib import Path
        >>> path2folder = Path(__file__).parent / "tests" / \
"integration" / "input_files"
        >>> path2sc = path2folder / "sc_ad_handmade.txt"
        >>> path2forms = path2folder / "forms_3cogs_wot.csv"
        >>> adrc_obj = Adrc(\
scdictlist=path2sc, \
formscsv=path2forms, \
srclg="WOT", \
tgtlg="EAH")
        >>> adrc_obj.get_nse("dade", "dady")
        33.25
        >>> adrc_obj.get_nse("dade", "dady", se=False)
        [[1, 2], [0], [1, 2], [3]]
        >>> adrc_obj.get_nse("dade", "dady", show_workflow=True)
        (33.25, 133, [1, 6, 1, 125])
        """
        # self.align can't handle empty strings as input!
        if (not left or not right) and show_workflow is False: return 0
        if (not left or not right) and show_workflow is True: return (
        0, 0, [0], [])
        # align the two input strings
        dfsc = self.align(left, right)
        # turn alignment-df into one pandas Series of sound correspondences
        sc = dfsc["vals"] + self.connector + dfsc["keys"] if self.mode == "\
adapt"  else dfsc["keys"] + self.connector + dfsc["vals"]
        # read nr of examples for each sound corresp in sum-of-examples-dict
        outlist = [self.sedict.get(i, 0) for i in sc]
        # add up the nr of examples for each corresp in the word
        outsum = sum(outlist)
        # divide the sum through the length of the word, round on 2 decimals
        normalised_outsum = round(outsum / len(dfsc), 2)
        # add the in-between-steps if indicated so (useful for debugging)
        if show_workflow is True:
            return normalised_outsum, outsum, str(outlist), str(list(sc))
        # return only the normalised value (nse) if show_workflow is not True
        return normalised_outsum
